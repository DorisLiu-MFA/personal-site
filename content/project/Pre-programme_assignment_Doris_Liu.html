---
title: 'MFA 2022 Pre-programme Assignment'
author: "Doris Liu"
date: "2021-10-18"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    toc: yes
    toc_float: yes
---



<div id="task-1-biography-of-doris-liu" class="section level2">
<h2>Task 1: Biography of Doris Liu</h2>
<p><strong>Doris Liu</strong><br />
<a href="www.linkedin.com/in/xinyi-doris-liu">LinkedIn</a></p>
<p><strong>Doris Liu</strong> <em>(Chinese name Xinyi Liu)</em> is from Shanghai, China. She is now pursuing a <strong>Masters in Financial Analysis degree</strong> at <strong>London Business School</strong> after graduating with a BS degree in Statistics at Fudan University in China. Being one with love for financial vehicles and a sense of digits, Doris has strong incentives to work on trading desks so she is now working hard to apply for <strong>Sales and Trading/Markets</strong> summer interships.</p>
<p><strong>Three thing that makes Doris unique:</strong><br />
- Dancer: Jazz, Urban, Kpop<br />
- Harry Potter fan: Magic knowledge well-equipped<br />
- Strong analytical and coding skills: In Stats</p>
</div>
<div id="task-2-gapminder-country-comparison" class="section level2">
<h2>Task 2: <code>gapminder</code> country comparison</h2>
<p>I explored the <code>gapminder</code> dataset that has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007.</p>
<pre class="r"><code>glimpse(gapminder)</code></pre>
<pre><code>## Rows: 1,704
## Columns: 6
## $ country   &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, ~
## $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, ~
## $ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, ~
## $ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8~
## $ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12~
## $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, ~</code></pre>
<pre class="r"><code>head(gapminder, 20) # look at the first 20 rows of the dataframe</code></pre>
<pre><code>## # A tibble: 20 x 6
##    country     continent  year lifeExp      pop gdpPercap
##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
##  1 Afghanistan Asia       1952    28.8  8425333      779.
##  2 Afghanistan Asia       1957    30.3  9240934      821.
##  3 Afghanistan Asia       1962    32.0 10267083      853.
##  4 Afghanistan Asia       1967    34.0 11537966      836.
##  5 Afghanistan Asia       1972    36.1 13079460      740.
##  6 Afghanistan Asia       1977    38.4 14880372      786.
##  7 Afghanistan Asia       1982    39.9 12881816      978.
##  8 Afghanistan Asia       1987    40.8 13867957      852.
##  9 Afghanistan Asia       1992    41.7 16317921      649.
## 10 Afghanistan Asia       1997    41.8 22227415      635.
## 11 Afghanistan Asia       2002    42.1 25268405      727.
## 12 Afghanistan Asia       2007    43.8 31889923      975.
## 13 Albania     Europe     1952    55.2  1282697     1601.
## 14 Albania     Europe     1957    59.3  1476505     1942.
## 15 Albania     Europe     1962    64.8  1728137     2313.
## 16 Albania     Europe     1967    66.2  1984060     2760.
## 17 Albania     Europe     1972    67.7  2263554     3313.
## 18 Albania     Europe     1977    68.9  2509048     3533.
## 19 Albania     Europe     1982    70.4  2780097     3631.
## 20 Albania     Europe     1987    72    3075321     3739.</code></pre>
<p>To produce two graphs of how life expectancy has changed over the years for the <em>country</em> and the <em>continent</em> I come from, I created the <code>country_data</code> and <code>continent_data</code> with the code below.</p>
<pre class="r"><code>country_data &lt;- gapminder %&gt;% 
            filter(country == &quot;China&quot;) # China is where I come from

continent_data &lt;- gapminder %&gt;% 
            filter(continent == &quot;Asia&quot;)</code></pre>
<p>First is a plot of life expectancy over time for the single country I chose, which is China.</p>
<pre class="r"><code>plot1 &lt;- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
 geom_point() +
 geom_smooth(se = FALSE) + NULL

plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/lifeExp_one_country-1.png" width="672" /></p>
<p>A title added to the plot.</p>
<pre class="r"><code>plot1&lt;- plot1 +
 labs(title = &quot;Plot of life expectancy over time for China&quot;,
     x = &quot;Year&quot;,
     y = &quot;Life Expectancy&quot;) + NULL

plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/lifeExp_one_country_with_label-1.png" width="672" /></p>
<p>Second is a plot for all countries in the <em>continent</em> I come from, which is Asia.</p>
<pre class="r"><code>ggplot(continent_data, mapping = aes(x = year, y = lifeExp, colour= country, group =country))+
 geom_point() + 
 geom_smooth(se = FALSE) + NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/lifeExp_one_continent-1.png" width="672" /></p>
<p>The final analysis explores life expectancy over time for different continents.</p>
<pre class="r"><code>ggplot(data = gapminder , mapping = aes(x = year, y = lifeExp, colour= continent))+
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_wrap(~continent) +
  theme(legend.position=&quot;none&quot;) + #remove all legends
  NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/lifeExp_facet_by_continent-1.png" width="672" /></p>
<blockquote>
<p>Conclusions about life expectancy since 1952:</p>
</blockquote>
<p>In terms of trends, since 1952, there have been quicker increases in life expectancies of American and Asian countries, while this growth appears to be slower in Europe and Oceania. Life expectancies seem to have stayed unchanged since 1990 in Africa.<br />
When it comes to country distributions, life expectancies of different countries in Americas, Europe and Oceania are more similar to each other, while those of African and Aisan countries disperse.</p>
</div>
<div id="task-3-brexit-vote-analysis" class="section level2">
<h2>Task 3: Brexit vote analysis</h2>
<p>Have a quick glimpse at the 2016 Brexit vote data in the UK from <a href="https://www.thecrosstab.com/">Elliott Morris</a>.<br />
Variables:<br />
- The main outcome variable (or y) is <code>leave_share</code>, which is the percent of votes cast in favour of Brexit, or leaving the EU.<br />
- Each row is a UK <a href="https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies">parliament constituency</a>.</p>
<pre class="r"><code>brexit_results &lt;- read_csv(here::here(&quot;data_project&quot;,&quot;brexit_results.csv&quot;))

glimpse(brexit_results)</code></pre>
<pre><code>## Rows: 632
## Columns: 11
## $ Seat        &lt;chr&gt; &quot;Aldershot&quot;, &quot;Aldridge-Brownhills&quot;, &quot;Altrincham and Sale W~
## $ con_2015    &lt;dbl&gt; 50.592, 52.050, 52.994, 43.979, 60.788, 22.418, 52.454, 22~
## $ lab_2015    &lt;dbl&gt; 18.333, 22.369, 26.686, 34.781, 11.197, 41.022, 18.441, 49~
## $ ld_2015     &lt;dbl&gt; 8.824, 3.367, 8.383, 2.975, 7.192, 14.828, 5.984, 2.423, 1~
## $ ukip_2015   &lt;dbl&gt; 17.867, 19.624, 8.011, 15.887, 14.438, 21.409, 18.821, 21.~
## $ leave_share &lt;dbl&gt; 57.89777, 67.79635, 38.58780, 65.29912, 49.70111, 70.47289~
## $ born_in_uk  &lt;dbl&gt; 83.10464, 96.12207, 90.48566, 97.30437, 93.33793, 96.96214~
## $ male        &lt;dbl&gt; 49.89896, 48.92951, 48.90621, 49.21657, 48.00189, 49.17185~
## $ unemployed  &lt;dbl&gt; 3.637000, 4.553607, 3.039963, 4.261173, 2.468100, 4.742731~
## $ degree      &lt;dbl&gt; 13.870661, 9.974114, 28.600135, 9.336294, 18.775591, 6.085~
## $ age_18to24  &lt;dbl&gt; 9.406093, 7.325850, 6.437453, 7.747801, 5.734730, 8.209863~</code></pre>
<p>I plotted a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.</p>
<pre class="r"><code># histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) + 
  labs(title = &quot;Histogram&quot;,
       subtitle=&quot;leave share in all constituencies&quot;,
       x = &quot;leave share (leave %)&quot;,
       y = &quot;count&quot;) + NULL</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/brexit_histogram-1.png" width="672" /></p>
<pre class="r"><code># density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() +
  labs(title = &quot;Density plot&quot;,
       subtitle=&quot;leave share in all constituencies&quot;,
       x = &quot;leave share (leave %)&quot;,
       y = &quot;density&quot;) </code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/brexit_histogram-2.png" width="672" /></p>
<pre class="r"><code># The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = &quot;Empirical cumulative distribution function (ECDF)&quot;,
       subtitle=&quot;leave share in all constituencies&quot;,
       x = &quot;leave share (leave %)&quot;,
       y = NULL) </code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/brexit_histogram-3.png" width="672" /></p>
<p>One common explanation for the Brexit outcome was fear of immigration and opposition to the EU’s more open border policy. To check the relationship (or correlation) between the proportion of native born residents (<code>born_in_uk</code>) in a constituency and its <code>leave_share</code>, I got the correlation between the two variables. The correlation is almost 0.5, which shows that the two variables are positively correlated.</p>
<pre class="r"><code>brexit_results %&gt;% 
  select(leave_share, born_in_uk) %&gt;% 
  cor()</code></pre>
<pre><code>##             leave_share born_in_uk
## leave_share   1.0000000  0.4934295
## born_in_uk    0.4934295  1.0000000</code></pre>
<p>The scatterplot between these two variables tells similar story.</p>
<pre class="r"><code>ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method=&quot;lm&quot; to get the best straight-line
  geom_smooth(method = &quot;lm&quot;) + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  
  labs(title = &quot;Scatterplot&quot;,
       subtitle=&quot;Correlation between the proportion of native born residents and leave share&quot;,
       x = &quot;% of native born residents&quot;,
       y = &quot;leave share (leave %)&quot;) +  NULL</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/brexit_immigration_plot-1.png" width="672" /></p>
<blockquote>
<p>Conclusions about Brexit vote:</p>
</blockquote>
<p>The constituencies with higher proportions of native born residents show higher leave share, which means more native constituencies might fear more of immigration and thus they tend to leave EU because of its more open boarder policy.</p>
</div>
<div id="task-4-animal-rescue-incidents-attended-by-the-london-fire-brigade" class="section level2">
<h2>Task 4: Animal rescue incidents attended by the London Fire Brigade</h2>
<p>The next dataset explored is <a href="https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb">The London Fire Brigade</a> which attends a range of non-fire incidents (‘special services’, assistance to animals).</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv&quot;

animal_rescue &lt;- read_csv(url,
                          locale = locale(encoding = &quot;CP1252&quot;)) %&gt;% 
  janitor::clean_names()


glimpse(animal_rescue)</code></pre>
<pre><code>## Rows: 7,873
## Columns: 31
## $ incident_number               &lt;chr&gt; &quot;139091&quot;, &quot;275091&quot;, &quot;2075091&quot;, &quot;2872091&quot;~
## $ date_time_of_call             &lt;chr&gt; &quot;01/01/2009 03:01&quot;, &quot;01/01/2009 08:51&quot;, ~
## $ cal_year                      &lt;dbl&gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009~
## $ fin_year                      &lt;chr&gt; &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/0~
## $ type_of_incident              &lt;chr&gt; &quot;Special Service&quot;, &quot;Special Service&quot;, &quot;S~
## $ pump_count                    &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ~
## $ pump_hours_total              &lt;chr&gt; &quot;2&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ~
## $ hourly_notional_cost          &lt;dbl&gt; 255, 255, 255, 255, 255, 255, 255, 255, ~
## $ incident_notional_cost        &lt;chr&gt; &quot;510&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;~
## $ final_description             &lt;chr&gt; &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Red~
## $ animal_group_parent           &lt;chr&gt; &quot;Dog&quot;, &quot;Fox&quot;, &quot;Dog&quot;, &quot;Horse&quot;, &quot;Rabbit&quot;, ~
## $ originof_call                 &lt;chr&gt; &quot;Person (land line)&quot;, &quot;Person (land line~
## $ property_type                 &lt;chr&gt; &quot;House - single occupancy&quot;, &quot;Railings&quot;, ~
## $ property_category             &lt;chr&gt; &quot;Dwelling&quot;, &quot;Outdoor Structure&quot;, &quot;Outdoo~
## $ special_service_type_category &lt;chr&gt; &quot;Other animal assistance&quot;, &quot;Other animal~
## $ special_service_type          &lt;chr&gt; &quot;Animal assistance involving livestock -~
## $ ward_code                     &lt;chr&gt; &quot;E05011467&quot;, &quot;E05000169&quot;, &quot;E05000558&quot;, &quot;~
## $ ward                          &lt;chr&gt; &quot;Crystal Palace &amp; Upper Norwood&quot;, &quot;Woods~
## $ borough_code                  &lt;chr&gt; &quot;E09000008&quot;, &quot;E09000008&quot;, &quot;E09000029&quot;, &quot;~
## $ borough                       &lt;chr&gt; &quot;Croydon&quot;, &quot;Croydon&quot;, &quot;Sutton&quot;, &quot;Hilling~
## $ stn_ground_name               &lt;chr&gt; &quot;Norbury&quot;, &quot;Woodside&quot;, &quot;Wallington&quot;, &quot;Ru~
## $ uprn                          &lt;chr&gt; &quot;NULL&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;100021491149.00~
## $ street                        &lt;chr&gt; &quot;Waddington Way&quot;, &quot;Grasmere Road&quot;, &quot;Mill~
## $ usrn                          &lt;chr&gt; &quot;20500146.00&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;21401484~
## $ postcode_district             &lt;chr&gt; &quot;SE19&quot;, &quot;SE25&quot;, &quot;SM5&quot;, &quot;UB9&quot;, &quot;RM3&quot;, &quot;RM~
## $ easting_m                     &lt;chr&gt; &quot;NULL&quot;, &quot;534785&quot;, &quot;528041&quot;, &quot;504689&quot;, &quot;N~
## $ northing_m                    &lt;chr&gt; &quot;NULL&quot;, &quot;167546&quot;, &quot;164923&quot;, &quot;190685&quot;, &quot;N~
## $ easting_rounded               &lt;dbl&gt; 532350, 534750, 528050, 504650, 554650, ~
## $ northing_rounded              &lt;dbl&gt; 170050, 167550, 164950, 190650, 192350, ~
## $ latitude                      &lt;chr&gt; &quot;NULL&quot;, &quot;51.39095371&quot;, &quot;51.36894086&quot;, &quot;5~
## $ longitude                     &lt;chr&gt; &quot;NULL&quot;, &quot;-0.064166887&quot;, &quot;-0.161985191&quot;, ~</code></pre>
<p>First is quick counts of the number of incidents by year.</p>
<pre class="r"><code>animal_rescue %&gt;% 
  dplyr::group_by(cal_year) %&gt;% 
  summarise(count=n())</code></pre>
<pre><code>## # A tibble: 13 x 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   648</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  count(cal_year, name=&quot;count&quot;)</code></pre>
<pre><code>## # A tibble: 13 x 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   648</code></pre>
<p>Next is the analysis on number of incidents by animal group.</p>
<pre class="r"><code>animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %&gt;% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %&gt;% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))</code></pre>
<pre><code>## # A tibble: 28 x 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               3783   48.0 
##  2 Bird                              1631   20.7 
##  3 Dog                               1230   15.6 
##  4 Fox                                373    4.74
##  5 Unknown - Domestic Animal Or Pet   201    2.55
##  6 Horse                              195    2.48
##  7 Deer                               136    1.73
##  8 Unknown - Wild Animal               94    1.19
##  9 Squirrel                            68    0.86
## 10 Unknown - Heavy Livestock Animal    50    0.64
## # ... with 18 more rows</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  #count does the same thing as group_by and summarise
  # name = &quot;count&quot; will call the column with the counts &quot;count&quot; ( exciting, I know)
  # and &#39;sort=TRUE&#39; will sort them from max to min
  count(animal_group_parent, name=&quot;count&quot;, sort=TRUE) %&gt;% 
  mutate(percent = round(100*count/sum(count),2))</code></pre>
<pre><code>## # A tibble: 28 x 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               3783   48.0 
##  2 Bird                              1631   20.7 
##  3 Dog                               1230   15.6 
##  4 Fox                                373    4.74
##  5 Unknown - Domestic Animal Or Pet   201    2.55
##  6 Horse                              195    2.48
##  7 Deer                               136    1.73
##  8 Unknown - Wild Animal               94    1.19
##  9 Squirrel                            68    0.86
## 10 Unknown - Heavy Livestock Animal    50    0.64
## # ... with 18 more rows</code></pre>
<blockquote>
<p>Something strange in this table:</p>
</blockquote>
<p>There are two categories, Cat and cat, which might be typo causing data ambiguity.</p>
<p>The final analysis is to look at the notional cost for rescuing each of these animals. Fix <code>incident_notional_cost</code> to change it into a number and calculate summary statistics for each animal group.</p>
<pre class="r"><code># what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;character&quot;</code></pre>
<pre class="r"><code># readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue &lt;- animal_rescue %&gt;% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now &#39;double&#39; or numeric
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;double&quot;</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %&gt;% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()&gt;6) %&gt;% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %&gt;% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))</code></pre>
<pre><code>## # A tibble: 16 x 7
##    animal_group_parent      mean_incident_co~ median_incident_~ sd_incident_cost
##    &lt;chr&gt;                                &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;
##  1 Horse                                 740.               596            541. 
##  2 Cow                                   599.               436            451. 
##  3 Unknown - Wild Animal                 416.               333            322. 
##  4 Deer                                  415.               333            282. 
##  5 Unknown - Heavy Livesto~              374.               260            263. 
##  6 Fox                                   374.               328            205. 
##  7 Snake                                 356.               339            105. 
##  8 Dog                                   347.               298            168. 
##  9 Bird                                  344.               328            134. 
## 10 Cat                                   344.               326            160. 
## 11 Unknown - Domestic Anim~              326.               295            116. 
## 12 cat                                   324.               290             94.1
## 13 Hamster                               315.               290             95.0
## 14 Squirrel                              314.               326             56.7
## 15 Ferret                                309.               333             39.4
## 16 Rabbit                                309.               326             32.2
## # ... with 3 more variables: min_incident_cost &lt;dbl&gt;, max_incident_cost &lt;dbl&gt;,
## #   count &lt;int&gt;</code></pre>
<blockquote>
<p>Conclusions:</p>
</blockquote>
<p>My analysis in comparing the mean and the median for each animal group tells me that for most animal groups, mean incident costs are lower than median, which means for more than half of the incidents(positively skewed), it took smaller amount of costs compared with mean.<br />
The outliers are Squirrel, Ferret and Rabbit.</p>
<p>Exploration in the distribution of incident cost for each animal group is as follows:</p>
<pre class="r"><code># base_plot
base_plot &lt;- animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  filter(n()&gt;6) %&gt;% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = &quot;free&quot;)+
  theme_bw()

base_plot + geom_histogram()</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/plots_on_incident_cost_by_animal_group-1.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_density()</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/plots_on_incident_cost_by_animal_group-2.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_boxplot()</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/plots_on_incident_cost_by_animal_group-3.png" width="672" /></p>
<pre class="r"><code>base_plot + stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent)</code></pre>
<p><img src="/project/Pre-programme_assignment_Doris_Liu_files/figure-html/plots_on_incident_cost_by_animal_group-4.png" width="672" /></p>
<blockquote>
<p>Conclusions about incident notional costs in rescuing animals:</p>
</blockquote>
<p>Boxplot best communicates the variability of the <code>incident_notional_cost</code> values because it can show the 25%, 75% quantiles and median.<br />
1. Horses, deers, cows, foxes and other wild or heavy livestock animals are more expensive to rescue, probably due to their size and thus longer time to rescue. According to standard deviation of incident notional costs and boxplots, the costs to rescue these mentioned large-size animals also vary a lot.<br />
2. For cats and dogs, incident costs are lower and less diverse. Costs are even lower and less diverse for hamster，squirrel, ferret and rabbit.<br />
3. This correlation between animal size, incident cost and spread of values is possibly explained by that large animals are harder to control and might need more labour, time and materials to rescue.</p>
<p>Additional Information:<br />
- Who did you collaborate with: None<br />
- Approximately how much time did you spend on this problem set: 2.5 hours<br />
- What, if anything, gave you the most trouble: Though I have used R before, I haven’t used Rmarkdown so I spent some time learning and debugging.</p>
</div>
