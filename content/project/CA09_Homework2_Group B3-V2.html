---
title: "Session 4: Homework 2"
author: "Study group 3: Ismail Riahi, John Purcell, Parthivi Bansal, Ivo Margetich, Doris Liu, Xinyue Zhang, Jacopo Lorusso Caputi"
date: "2021-10-18"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---



<div id="task-1-climate-change-and-temperature-anomalies" class="section level1">
<h1>Task 1: Climate change and temperature anomalies</h1>
<p>First we use read_csv to get the data. When using this function, we added two options: <code>skip</code> and <code>na</code>.</p>
<ol style="list-style-type: decimal">
<li>The <code>skip=1</code> option is there as the real data table only starts in Row 2, so we need to skip one row.</li>
<li><code>na = "***"</code> option informs R how missing observations in the spreadsheet are coded. When looking at the spreadsheet, you can see that missing data is coded as "***". It is best to specify this here, as otherwise some of the data is not recognized as numeric data.</li>
</ol>
<pre class="r"><code>weather &lt;- 
  read_csv(&quot;https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv&quot;, 
           skip = 1, 
           na = &quot;***&quot;)</code></pre>
<pre class="r"><code>glimpse(weather)</code></pre>
<pre><code>## Rows: 142
## Columns: 19
## $ Year  &lt;dbl&gt; 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890~
## $ Jan   &lt;dbl&gt; -0.35, -0.30, 0.26, -0.58, -0.16, -1.01, -0.74, -1.08, -0.48, -0~
## $ Feb   &lt;dbl&gt; -0.51, -0.21, 0.21, -0.66, -0.11, -0.45, -0.83, -0.70, -0.61, 0.~
## $ Mar   &lt;dbl&gt; -0.23, -0.03, 0.02, -0.16, -0.64, -0.23, -0.72, -0.44, -0.64, -0~
## $ Apr   &lt;dbl&gt; -0.30, 0.01, -0.32, -0.30, -0.59, -0.48, -0.37, -0.38, -0.22, 0.~
## $ May   &lt;dbl&gt; -0.06, 0.04, -0.24, -0.25, -0.36, -0.59, -0.34, -0.25, -0.15, -0~
## $ Jun   &lt;dbl&gt; -0.16, -0.32, -0.30, -0.11, -0.41, -0.44, -0.37, -0.20, -0.03, -~
## $ Jul   &lt;dbl&gt; -0.18, 0.08, -0.28, -0.05, -0.44, -0.34, -0.14, -0.24, -0.01, -0~
## $ Aug   &lt;dbl&gt; -0.26, -0.04, -0.15, -0.22, -0.51, -0.41, -0.43, -0.54, -0.21, -~
## $ Sep   &lt;dbl&gt; -0.23, -0.26, -0.24, -0.34, -0.44, -0.40, -0.33, -0.21, -0.20, -~
## $ Oct   &lt;dbl&gt; -0.32, -0.43, -0.53, -0.16, -0.44, -0.37, -0.31, -0.49, -0.04, -~
## $ Nov   &lt;dbl&gt; -0.43, -0.36, -0.33, -0.44, -0.57, -0.38, -0.39, -0.27, -0.01, -~
## $ Dec   &lt;dbl&gt; -0.40, -0.22, -0.69, -0.15, -0.47, -0.11, -0.22, -0.43, -0.24, -~
## $ `J-D` &lt;dbl&gt; -0.28, -0.17, -0.21, -0.28, -0.43, -0.43, -0.43, -0.44, -0.24, -~
## $ `D-N` &lt;dbl&gt; NA, -0.19, -0.18, -0.33, -0.40, -0.46, -0.42, -0.42, -0.25, -0.1~
## $ DJF   &lt;dbl&gt; NA, -0.30, 0.08, -0.64, -0.14, -0.64, -0.56, -0.67, -0.51, -0.08~
## $ MAM   &lt;dbl&gt; -0.19, 0.01, -0.18, -0.24, -0.53, -0.43, -0.47, -0.36, -0.34, 0.~
## $ JJA   &lt;dbl&gt; -0.20, -0.09, -0.24, -0.13, -0.45, -0.40, -0.32, -0.33, -0.08, -~
## $ SON   &lt;dbl&gt; -0.33, -0.35, -0.37, -0.31, -0.49, -0.38, -0.35, -0.32, -0.08, -~</code></pre>
<pre class="r"><code>skimr::skim(weather)</code></pre>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
(#tab:glimpse and skim weather dataset)Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
weather
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
142
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
19
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
19
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Year
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
1950.50
</td>
<td style="text-align:right;">
41.14
</td>
<td style="text-align:right;">
1880.00
</td>
<td style="text-align:right;">
1915.25
</td>
<td style="text-align:right;">
1950.50
</td>
<td style="text-align:right;">
1985.75
</td>
<td style="text-align:right;">
2021.00
</td>
<td style="text-align:left;">
&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2587&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Jan
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:right;">
-1.52
</td>
<td style="text-align:right;">
-0.30
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
1.59
</td>
<td style="text-align:left;">
&lt;U+2581&gt;&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Feb
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.57
</td>
<td style="text-align:right;">
-0.97
</td>
<td style="text-align:right;">
-0.35
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
0.46
</td>
<td style="text-align:right;">
1.94
</td>
<td style="text-align:left;">
&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2586&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Mar
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
0.55
</td>
<td style="text-align:right;">
-0.80
</td>
<td style="text-align:right;">
-0.26
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.36
</td>
<td style="text-align:right;">
1.91
</td>
<td style="text-align:left;">
&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Apr
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
-0.66
</td>
<td style="text-align:right;">
-0.26
</td>
<td style="text-align:right;">
-0.01
</td>
<td style="text-align:right;">
0.30
</td>
<td style="text-align:right;">
1.49
</td>
<td style="text-align:left;">
&lt;U+2586&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
May
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.41
</td>
<td style="text-align:right;">
-0.74
</td>
<td style="text-align:right;">
-0.23
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.23
</td>
<td style="text-align:right;">
1.28
</td>
<td style="text-align:left;">
&lt;U+2582&gt;&lt;U+2587&gt;&lt;U+2585&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Jun
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
-0.52
</td>
<td style="text-align:right;">
-0.19
</td>
<td style="text-align:right;">
-0.04
</td>
<td style="text-align:right;">
0.22
</td>
<td style="text-align:right;">
1.21
</td>
<td style="text-align:left;">
&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Jul
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:right;">
-0.18
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:right;">
1.11
</td>
<td style="text-align:left;">
&lt;U+2583&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Aug
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
-0.78
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
-0.04
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:right;">
1.14
</td>
<td style="text-align:left;">
&lt;U+2582&gt;&lt;U+2587&gt;&lt;U+2586&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Sep
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.41
</td>
<td style="text-align:right;">
-0.81
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
1.22
</td>
<td style="text-align:left;">
&lt;U+2581&gt;&lt;U+2587&gt;&lt;U+2585&gt;&lt;U+2582&gt;&lt;U+2582&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Oct
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
-0.85
</td>
<td style="text-align:right;">
-0.20
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
1.31
</td>
<td style="text-align:left;">
&lt;U+2582&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2582&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Nov
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
-0.83
</td>
<td style="text-align:right;">
-0.23
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.31
</td>
<td style="text-align:right;">
1.62
</td>
<td style="text-align:left;">
&lt;U+2583&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
Dec
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
-1.15
</td>
<td style="text-align:right;">
-0.28
</td>
<td style="text-align:right;">
-0.03
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
1.53
</td>
<td style="text-align:left;">
&lt;U+2581&gt;&lt;U+2587&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
J-D
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
-0.58
</td>
<td style="text-align:right;">
-0.22
</td>
<td style="text-align:right;">
-0.01
</td>
<td style="text-align:right;">
0.24
</td>
<td style="text-align:right;">
1.36
</td>
<td style="text-align:left;">
&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
D-N
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:right;">
-0.21
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.22
</td>
<td style="text-align:right;">
1.38
</td>
<td style="text-align:left;">
&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
DJF
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.52
</td>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:right;">
-0.28
</td>
<td style="text-align:right;">
-0.01
</td>
<td style="text-align:right;">
0.37
</td>
<td style="text-align:right;">
1.68
</td>
<td style="text-align:left;">
&lt;U+2582&gt;&lt;U+2587&gt;&lt;U+2586&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
MAM
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.47
</td>
<td style="text-align:right;">
-0.72
</td>
<td style="text-align:right;">
-0.24
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
0.27
</td>
<td style="text-align:right;">
1.50
</td>
<td style="text-align:left;">
&lt;U+2583&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
JJA
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
-0.54
</td>
<td style="text-align:right;">
-0.20
</td>
<td style="text-align:right;">
-0.03
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:right;">
1.13
</td>
<td style="text-align:left;">
&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2582&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
SON
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
-0.72
</td>
<td style="text-align:right;">
-0.23
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
1.35
</td>
<td style="text-align:left;">
&lt;U+2583&gt;&lt;U+2587&gt;&lt;U+2585&gt;&lt;U+2582&gt;&lt;U+2581&gt;
</td>
</tr>
</tbody>
</table>
<p>After selecting the year and the twelve month variables from the <code>weather</code> dataset, we convert the dataframe from wide to ‘long’ format using pivot_longer()<code>function. We name the new dataframe as</code>tidyweather<code>, name the variable containing the name of the month as</code>month<code>, and the temperature deviation values as</code>delta`.</p>
<p>The dataframe now has three variables:
1. year,
2. month, and
3. delta, or temperature deviation.</p>
<pre class="r"><code># 1. Select
weather &lt;- weather %&gt;% 
  select(Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec )

# 2. Long Format
tidyweather &lt;- weather %&gt;% 
  pivot_longer(cols=2:13, 
               names_to=&quot;Month&quot;, 
               values_to = &quot;Delta&quot;)

tidyweather</code></pre>
<pre><code>## # A tibble: 1,704 x 3
##     Year Month Delta
##    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
##  1  1880 Jan   -0.35
##  2  1880 Feb   -0.51
##  3  1880 Mar   -0.23
##  4  1880 Apr   -0.3 
##  5  1880 May   -0.06
##  6  1880 Jun   -0.16
##  7  1880 Jul   -0.18
##  8  1880 Aug   -0.26
##  9  1880 Sep   -0.23
## 10  1880 Oct   -0.32
## # ... with 1,694 more rows</code></pre>
<div id="plotting-weather-anomalies" class="section level2">
<h2>Plotting weather anomalies</h2>
<pre class="r"><code>tidyweather &lt;- tidyweather %&gt;%
  mutate(date = ymd(paste(as.character(Year), Month, &quot;1&quot;)),
         month = month(date, label=TRUE),
         year = year(date))

ggplot(tidyweather, aes(x=date, y = Delta))+
  geom_point()+
  geom_smooth(color=&quot;red&quot;) +
  theme_bw() +
  labs (
    title = &quot;Weather Anomalies&quot;
  )</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/scatter_plot-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>Then we plot to see whether the effect of increasing temperature more pronounced in some months.</p>
<pre class="r"><code>ggplot(tidyweather, aes(x=date, y = Delta))+
  geom_point()+
  geom_smooth(color=&quot;red&quot;) +
  facet_wrap(~month)+
  theme_bw() +
  labs (
    title = &quot;Weather Anomalies&quot;
  )</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/facet_wrap-1.png" width="1152" style="display: block; margin: auto;" />
It seems that increasing temperatures are found in all months with the highest values in February and March</p>
<p>The code below creates a new data frame grouping data in five time periods: 1881-1920, 1921-1950, 1951-1980, 1981-2010 and 2011-present.</p>
<pre class="r"><code>comparison &lt;- tidyweather %&gt;% 
  filter(Year&gt;= 1881) %&gt;%     #remove years prior to 1881
  #create new variable &#39;interval&#39;, and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ &quot;1881-1920&quot;,
    Year %in% c(1921:1950) ~ &quot;1921-1950&quot;,
    Year %in% c(1951:1980) ~ &quot;1951-1980&quot;,
    Year %in% c(1981:2010) ~ &quot;1981-2010&quot;,
    TRUE ~ &quot;2011-present&quot;
  ))</code></pre>
<p>Now we create a density plot to study the distribution of monthly deviations grouped by the different time periods we are interested in.</p>
<pre class="r"><code>ggplot(comparison, aes(x=Delta, fill=interval))+
  geom_density(alpha=0.2) +   #density plot with tranparency set to 20%
  theme_bw() +                #theme
  labs (
    title = &quot;Density Plot for Monthly Temperature Anomalies&quot;,
    y     = &quot;Density&quot;,
    x = &quot;Delta&quot; #changing y-axis label to sentence case
  )</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/density_plot-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>So far, we have been working with monthly anomalies. However, we might be interested in average annual anomalies. We can do this by using <code>group_by()</code> and <code>summarise()</code>, followed by a scatter plot to display the result.</p>
<pre class="r"><code>average_annual_anomaly &lt;- tidyweather %&gt;% 
  group_by(Year) %&gt;%   
  summarise(annual_mean_delta = mean(Delta, na.rm=TRUE)) 

ggplot(average_annual_anomaly, aes(x=Year, y= annual_mean_delta))+
  geom_point()+
  geom_smooth() +
  theme_bw() +
  labs (
    title = &quot;Average Yearly Anomaly&quot;,
    y     = &quot;Average Annual Delta&quot;
  )                         </code></pre>
</div>
<div id="confidence-interval-for-delta" class="section level2">
<h2>Confidence Interval for <code>Delta</code></h2>
<p><a href="https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php">NASA points out on their website</a> that
&gt; A one-degree global change is significant because it takes a vast amount of heat to warm all the oceans, atmosphere, and land by that much. In the past, a one- to two-degree drop was all it took to plunge the Earth into the Little Ice Age.</p>
<p>We constructed a confidence interval for the average annual delta since 2011.</p>
<pre class="r"><code>formula_ci &lt;- comparison %&gt;% 
  filter(interval==&quot;2011-present&quot;) %&gt;% 
  summarize(mean_delta = mean(Delta, na.rm=TRUE), 
            sd_delta = sd(Delta, na.rm=TRUE),
            count=n(),
            se_delta = sd_delta/sqrt(count),
            t_critical = qt(0.975, count-1),
            upper_bound = mean_delta+t_critical*se_delta,
            lower_bound = mean_delta-t_critical*se_delta
            )
  
formula_ci</code></pre>
<pre class="r"><code>set.seed(1234)
bootstrap_delta &lt;- comparison %&gt;% 
  filter(interval==&quot;2011-present&quot;) %&gt;% 
  specify(response = Delta) %&gt;% 
  generate(reps=10000, type=&quot;bootstrap&quot;) %&gt;% 
  calculate(stat=c(&quot;mean&quot;))
  
bootstrap_ci &lt;- bootstrap_delta %&gt;% 
  get_ci(level=0.95, type=&quot;percentile&quot;)

bootstrap_ci</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     1.01     1.11</code></pre>
<blockquote>
<p>The data points constitute the confidence interval, that we are 95% sure that it includes the true mean annual delta.</p>
</blockquote>
</div>
</div>
<div id="task-2-global-warming-and-political-views-gss" class="section level1">
<h1>Task 2: Global warming and political views (GSS)</h1>
<p><a href="https://www.pewresearch.org/2010/10/27/wide-partisan-divide-over-global-warming/">A 2010 Pew Research poll</a> asked 1,306 Americans, “From what you’ve read and heard, is there solid evidence that the average temperature on earth has been getting warmer over the past few decades, or not?”</p>
<p>Here we analyze whether there are any differences between the proportion of people who believe the earth is getting warmer and their political ideology. From the <strong>survey sample data</strong>, we will use the proportions to estimate values of <em>population parameters</em>. The file has 2253 observations on the following 2 variables:</p>
<ul>
<li><code>party_or_ideology</code>: a factor (categorical) variable with levels Conservative Republican, Liberal Democrat, Mod/Cons Democrat, Mod/Lib Republican</li>
<li><code>response</code> : whether the respondent believes the earth is warming or not, or Don’t know/ refuse to answer</li>
</ul>
<pre class="r"><code>global_warming_pew &lt;- read_csv(here::here(&quot;data_project&quot;, &quot;global_warming_pew.csv&quot;))
glimpse(global_warming_pew)</code></pre>
<pre><code>## Rows: 2,253
## Columns: 2
## $ party_or_ideology &lt;chr&gt; &quot;Conservative Republican&quot;, &quot;Conservative Republican&quot;~
## $ response          &lt;chr&gt; &quot;Earth is warming&quot;, &quot;Earth is warming&quot;, &quot;Earth is wa~</code></pre>
<pre class="r"><code>global_warming_pew &lt;- global_warming_pew %&gt;% 
  filter(response!=&quot;Don&#39;t know / refuse to answer&quot;) %&gt;%
  count(party_or_ideology, response)

global_warming_pew</code></pre>
<pre><code>## # A tibble: 8 x 3
##   party_or_ideology       response             n
##   &lt;chr&gt;                   &lt;chr&gt;            &lt;int&gt;
## 1 Conservative Republican Earth is warming   248
## 2 Conservative Republican Not warming        450
## 3 Liberal Democrat        Earth is warming   405
## 4 Liberal Democrat        Not warming         23
## 5 Mod/Cons Democrat       Earth is warming   563
## 6 Mod/Cons Democrat       Not warming        158
## 7 Mod/Lib Republican      Earth is warming   135
## 8 Mod/Lib Republican      Not warming        135</code></pre>
<p>We then construct 95% confidence intervals to estimate population parameters, for the % who believe that <strong>Earth is warming</strong>, according to their party or ideology.
Methods include creating the CIs using the formulas by hand, or using <code>prop.test()</code>.</p>
<pre class="r"><code>global_warming_pew %&gt;% 
  filter(response==c(&quot;Earth is warming&quot;, &quot;Not warming&quot;)) %&gt;%
  # count(party_or_ideology, response) %&gt;% 
  pivot_wider(names_from = response, values_from=n) %&gt;% 
  clean_names() %&gt;%
  mutate(
    total=earth_is_warming + not_warming,
    prop = earth_is_warming/total,
    se=sqrt(prop*(1-prop)/total),
    lower_bound = prop - 1.96*se,
    upper_bound = prop + 1.96*se
  )</code></pre>
<pre><code>## # A tibble: 4 x 8
##   party_or_ideology       earth_is_warming not_warming total  prop     se lower_bound
##   &lt;chr&gt;                              &lt;int&gt;       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;
## 1 Conservative Republican              248         450   698 0.355 0.0181       0.320
## 2 Liberal Democrat                     405          23   428 0.946 0.0109       0.925
## 3 Mod/Cons Democrat                    563         158   721 0.781 0.0154       0.751
## 4 Mod/Lib Republican                   135         135   270 0.5   0.0304       0.440
## # ... with 1 more variable: upper_bound &lt;dbl&gt;</code></pre>
<p>We constructed 95% confidence intervals to estimate population parameters, for the % who believe that <strong>Earth is warming</strong>, according to their party or ideology.</p>
<p>It appers that beliefs on climate change are different according to political ideology - the more liberal a person the more probable they are to believe in climate change as opposed to conservatives tending to discard the statement that earth is warming.</p>
<p>For further information read <a href="https://www.brookings.edu/research/the-challenging-politics-of-climate-change/">The challenging politics of climate change</a></p>
</div>
<div id="task-3-bidens-approval-margins" class="section level1">
<h1>Task 3: Biden’s Approval Margins</h1>
<p>We import Biden’s approval dataset from fivethirtyeight.com <a href="https://projects.fivethirtyeight.com/biden-approval-ratings">all polls that track the president’s approval</a>, and use <code>lubridate</code> to fix dates.</p>
<pre class="r"><code># Import approval polls data directly off fivethirtyeight website
approval_polllist &lt;- read_csv(&#39;https://projects.fivethirtyeight.com/biden-approval-data/approval_polllist.csv&#39;) 

glimpse(approval_polllist)</code></pre>
<pre><code>## Rows: 1,918
## Columns: 22
## $ president           &lt;chr&gt; &quot;Joseph R. Biden Jr.&quot;, &quot;Joseph R. Biden Jr.&quot;, &quot;Jos~
## $ subgroup            &lt;chr&gt; &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;~
## $ modeldate           &lt;chr&gt; &quot;10/15/2021&quot;, &quot;10/15/2021&quot;, &quot;10/15/2021&quot;, &quot;10/15/2~
## $ startdate           &lt;chr&gt; &quot;1/19/2021&quot;, &quot;1/19/2021&quot;, &quot;1/20/2021&quot;, &quot;1/20/2021&quot;~
## $ enddate             &lt;chr&gt; &quot;1/21/2021&quot;, &quot;1/21/2021&quot;, &quot;1/21/2021&quot;, &quot;1/22/2021&quot;~
## $ pollster            &lt;chr&gt; &quot;Morning Consult&quot;, &quot;Rasmussen Reports/Pulse Opinio~
## $ grade               &lt;chr&gt; &quot;B&quot;, &quot;B&quot;, &quot;B+&quot;, &quot;B&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B-&quot;, &quot;B~
## $ samplesize          &lt;dbl&gt; 15000, 1500, 1516, 15000, 1115, 1993, 15000, 1500,~
## $ population          &lt;chr&gt; &quot;a&quot;, &quot;lv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;lv&quot;, &quot;rv&quot;, &quot;~
## $ weight              &lt;dbl&gt; 0.2594, 0.3382, 1.2454, 0.2333, 1.1014, 0.0930, 0.~
## $ influence           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ approve             &lt;dbl&gt; 50, 48, 45, 51, 55, 56, 52, 48, 58, 63, 54, 55, 48~
## $ disapprove          &lt;dbl&gt; 28, 45, 28, 28, 32, 31, 29, 47, 32, 37, 30, 33, 47~
## $ adjusted_approve    &lt;dbl&gt; 48.6, 50.5, 46.5, 49.6, 53.9, 54.6, 50.6, 50.5, 57~
## $ adjusted_disapprove &lt;dbl&gt; 31.2, 38.8, 28.4, 31.2, 33.0, 34.2, 32.2, 40.8, 33~
## $ multiversions       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~
## $ tracking            &lt;lgl&gt; TRUE, TRUE, NA, TRUE, NA, NA, TRUE, TRUE, NA, NA, ~
## $ url                 &lt;chr&gt; &quot;https://morningconsult.com/form/global-leader-app~
## $ poll_id             &lt;dbl&gt; 74272, 74247, 74327, 74273, 74248, 74246, 74274, 7~
## $ question_id         &lt;dbl&gt; 139491, 139395, 139570, 139492, 139404, 139394, 13~
## $ createddate         &lt;chr&gt; &quot;1/28/2021&quot;, &quot;1/22/2021&quot;, &quot;2/2/2021&quot;, &quot;1/28/2021&quot;,~
## $ timestamp           &lt;chr&gt; &quot;13:12:11 15 Oct 2021&quot;, &quot;13:12:11 15 Oct 2021&quot;, &quot;1~</code></pre>
<pre class="r"><code>skim(approval_polllist)</code></pre>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
(#tab:import biden approval dataset and fix dates)Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
approval_polllist
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
1918
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
22
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
character
</td>
<td style="text-align:left;">
12
</td>
</tr>
<tr>
<td style="text-align:left;">
logical
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
empty
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:right;">
whitespace
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
president
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
subgroup
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
modeldate
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
startdate
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
enddate
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
267
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
pollster
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
47
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
grade
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
0.98
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
population
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
multiversions
</td>
<td style="text-align:right;">
1884
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
url
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
33
</td>
<td style="text-align:right;">
275
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
461
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
createddate
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
202
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
timestamp
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: logical</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:left;">
count
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
tracking
</td>
<td style="text-align:right;">
994
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
TRU: 924
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
samplesize
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.39e+03
</td>
<td style="text-align:right;">
6113.70
</td>
<td style="text-align:right;">
515.0
</td>
<td style="text-align:right;">
1.27e+03
</td>
<td style="text-align:right;">
1.50e+03
</td>
<td style="text-align:right;">
15000.0
</td>
<td style="text-align:right;">
2.20e+04
</td>
<td style="text-align:left;">
&lt;U+2587&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2583&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
weight
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.70e-01
</td>
<td style="text-align:right;">
0.59
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
1.20e-01
</td>
<td style="text-align:right;">
2.10e-01
</td>
<td style="text-align:right;">
0.9
</td>
<td style="text-align:right;">
3.16e+00
</td>
<td style="text-align:left;">
&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
influence
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2.00e-02
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
0.00e+00
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
1.19e+00
</td>
<td style="text-align:left;">
&lt;U+2587&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
approve
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.15e+01
</td>
<td style="text-align:right;">
4.38
</td>
<td style="text-align:right;">
38.0
</td>
<td style="text-align:right;">
4.80e+01
</td>
<td style="text-align:right;">
5.20e+01
</td>
<td style="text-align:right;">
54.0
</td>
<td style="text-align:right;">
6.30e+01
</td>
<td style="text-align:left;">
&lt;U+2581&gt;&lt;U+2585&gt;&lt;U+2587&gt;&lt;U+2586&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
disapprove
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.25e+01
</td>
<td style="text-align:right;">
5.93
</td>
<td style="text-align:right;">
28.0
</td>
<td style="text-align:right;">
3.80e+01
</td>
<td style="text-align:right;">
4.20e+01
</td>
<td style="text-align:right;">
47.0
</td>
<td style="text-align:right;">
5.80e+01
</td>
<td style="text-align:left;">
&lt;U+2582&gt;&lt;U+2587&gt;&lt;U+2586&gt;&lt;U+2585&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
adjusted_approve
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.13e+01
</td>
<td style="text-align:right;">
3.69
</td>
<td style="text-align:right;">
40.4
</td>
<td style="text-align:right;">
4.94e+01
</td>
<td style="text-align:right;">
5.18e+01
</td>
<td style="text-align:right;">
53.6
</td>
<td style="text-align:right;">
6.35e+01
</td>
<td style="text-align:left;">
&lt;U+2581&gt;&lt;U+2583&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
adjusted_disapprove
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.24e+01
</td>
<td style="text-align:right;">
4.42
</td>
<td style="text-align:right;">
27.3
</td>
<td style="text-align:right;">
3.92e+01
</td>
<td style="text-align:right;">
4.20e+01
</td>
<td style="text-align:right;">
45.1
</td>
<td style="text-align:right;">
5.52e+01
</td>
<td style="text-align:left;">
&lt;U+2581&gt;&lt;U+2583&gt;&lt;U+2587&gt;&lt;U+2583&gt;&lt;U+2581&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
poll_id
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
7.52e+04
</td>
<td style="text-align:right;">
705.73
</td>
<td style="text-align:right;">
74246.0
</td>
<td style="text-align:right;">
7.46e+04
</td>
<td style="text-align:right;">
7.49e+04
</td>
<td style="text-align:right;">
75638.0
</td>
<td style="text-align:right;">
7.68e+04
</td>
<td style="text-align:left;">
&lt;U+2587&gt;&lt;U+2586&gt;&lt;U+2583&gt;&lt;U+2582&gt;&lt;U+2583&gt;
</td>
</tr>
<tr>
<td style="text-align:left;">
question_id
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.43e+05
</td>
<td style="text-align:right;">
2089.97
</td>
<td style="text-align:right;">
139394.0
</td>
<td style="text-align:right;">
1.40e+05
</td>
<td style="text-align:right;">
1.43e+05
</td>
<td style="text-align:right;">
144272.8
</td>
<td style="text-align:right;">
1.46e+05
</td>
<td style="text-align:left;">
&lt;U+2587&gt;&lt;U+2581&gt;&lt;U+2586&gt;&lt;U+2585&gt;&lt;U+2583&gt;
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># Use `lubridate` to fix dates, as they are given as characters.
approval_polllist &lt;- approval_polllist %&gt;%
  mutate(modeldate = mdy(modeldate)) %&gt;%
  mutate(startdate = mdy(startdate)) %&gt;%
  mutate(enddate = mdy(enddate)) %&gt;%
  mutate(createddate = mdy(createddate))
str(approval_polllist)</code></pre>
<pre><code>## spec_tbl_df [1,918 x 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ president          : chr [1:1918] &quot;Joseph R. Biden Jr.&quot; &quot;Joseph R. Biden Jr.&quot; &quot;Joseph R. Biden Jr.&quot; &quot;Joseph R. Biden Jr.&quot; ...
##  $ subgroup           : chr [1:1918] &quot;All polls&quot; &quot;All polls&quot; &quot;All polls&quot; &quot;All polls&quot; ...
##  $ modeldate          : Date[1:1918], format: &quot;2021-10-15&quot; &quot;2021-10-15&quot; ...
##  $ startdate          : Date[1:1918], format: &quot;2021-01-19&quot; &quot;2021-01-19&quot; ...
##  $ enddate            : Date[1:1918], format: &quot;2021-01-21&quot; &quot;2021-01-21&quot; ...
##  $ pollster           : chr [1:1918] &quot;Morning Consult&quot; &quot;Rasmussen Reports/Pulse Opinion Research&quot; &quot;YouGov&quot; &quot;Morning Consult&quot; ...
##  $ grade              : chr [1:1918] &quot;B&quot; &quot;B&quot; &quot;B+&quot; &quot;B&quot; ...
##  $ samplesize         : num [1:1918] 15000 1500 1516 15000 1115 ...
##  $ population         : chr [1:1918] &quot;a&quot; &quot;lv&quot; &quot;a&quot; &quot;a&quot; ...
##  $ weight             : num [1:1918] 0.259 0.338 1.245 0.233 1.101 ...
##  $ influence          : num [1:1918] 0 0 0 0 0 0 0 0 0 0 ...
##  $ approve            : num [1:1918] 50 48 45 51 55 56 52 48 58 63 ...
##  $ disapprove         : num [1:1918] 28 45 28 28 32 31 29 47 32 37 ...
##  $ adjusted_approve   : num [1:1918] 48.6 50.5 46.5 49.6 53.9 ...
##  $ adjusted_disapprove: num [1:1918] 31.2 38.8 28.4 31.2 33 ...
##  $ multiversions      : chr [1:1918] NA NA NA NA ...
##  $ tracking           : logi [1:1918] TRUE TRUE NA TRUE NA NA ...
##  $ url                : chr [1:1918] &quot;https://morningconsult.com/form/global-leader-approval/&quot; &quot;https://www.rasmussenreports.com/public_content/politics/biden_administration/biden_approval_index_history&quot; &quot;https://docs.cdn.yougov.com/u3h9dresbn/20210120_yahoo_coronavirus_toplines.pdf&quot; &quot;https://morningconsult.com/form/global-leader-approval/&quot; ...
##  $ poll_id            : num [1:1918] 74272 74247 74327 74273 74248 ...
##  $ question_id        : num [1:1918] 139491 139395 139570 139492 139404 ...
##  $ createddate        : Date[1:1918], format: &quot;2021-01-28&quot; &quot;2021-01-22&quot; ...
##  $ timestamp          : chr [1:1918] &quot;13:12:11 15 Oct 2021&quot; &quot;13:12:11 15 Oct 2021&quot; &quot;13:12:11 15 Oct 2021&quot; &quot;13:12:11 15 Oct 2021&quot; ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   president = col_character(),
##   ..   subgroup = col_character(),
##   ..   modeldate = col_character(),
##   ..   startdate = col_character(),
##   ..   enddate = col_character(),
##   ..   pollster = col_character(),
##   ..   grade = col_character(),
##   ..   samplesize = col_double(),
##   ..   population = col_character(),
##   ..   weight = col_double(),
##   ..   influence = col_double(),
##   ..   approve = col_double(),
##   ..   disapprove = col_double(),
##   ..   adjusted_approve = col_double(),
##   ..   adjusted_disapprove = col_double(),
##   ..   multiversions = col_character(),
##   ..   tracking = col_logical(),
##   ..   url = col_character(),
##   ..   poll_id = col_double(),
##   ..   question_id = col_double(),
##   ..   createddate = col_character(),
##   ..   timestamp = col_character()
##   .. )
##  - attr(*, &quot;problems&quot;)=&lt;externalptr&gt;</code></pre>
<div id="average-net-approval-rate" class="section level2">
<h2>Average net approval rate</h2>
<p>Then we calculate the average net approval rate (approve- disapprove) for each week since he got into office (Jan 20th 2021), and get the mean, standard deviation, and 95% confidence interval of the weekly net approval.</p>
<pre class="r"><code>approval_polllist_avg_approval &lt;- approval_polllist %&gt;%
  mutate(net_approval = approve-disapprove) %&gt;%
  mutate(end_week = week(enddate)) %&gt;%
  group_by(end_week)%&gt;%
  summarise(average_net_approval = mean(net_approval),
            sd_net_approval = sd(net_approval),
            count=n(),
            se_net_approval = sd_net_approval/sqrt(count),
            upper_bound = average_net_approval+se_net_approval*qt(0.975, count-1),
            lower_bound = average_net_approval-se_net_approval*qt(0.975, count-1))

approval_polllist_avg_approval</code></pre>
<pre><code>## # A tibble: 39 x 7
##    end_week average_net_approval sd_net_approval count se_net_approval upper_bound
##       &lt;dbl&gt;                &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;           &lt;dbl&gt;       &lt;dbl&gt;
##  1        3                 18.6            8.23    11            2.48        24.2
##  2        4                 18.5            8.94    51            1.25        21.0
##  3        5                 16.7            7.59    54            1.03        18.8
##  4        6                 16.6            8.16    37            1.34        19.3
##  5        7                 16.3            7.34    50            1.04        18.4
##  6        8                 15.0            7.77    50            1.10        17.2
##  7        9                 13.4            7.46    53            1.02        15.4
##  8       10                 12.9            7.08    49            1.01        15.0
##  9       11                 15.8            7.45    43            1.14        18.1
## 10       12                 14.7            9.32    57            1.23        17.2
## # ... with 29 more rows, and 1 more variable: lower_bound &lt;dbl&gt;</code></pre>
<p>Biden’s weekly average net approval rate plot is then generated, along with the smooth line and 95% confidence interval.</p>
<pre class="r"><code>ggplot(approval_polllist_avg_approval, aes(x=end_week,y=average_net_approval)) +
  geom_point(color=&quot;red&quot;)+
  geom_line(color=&quot;red&quot;)+
  geom_smooth(se=F,span=1)+
  geom_ribbon(aes(ymin=lower_bound,ymax=upper_bound),alpha=0.1,color=&quot;grey&quot;)+
  scale_y_continuous(limits=c(-10,25))+
  geom_hline(yintercept=0,color=&quot;orange&quot;,size=1.5)+
  theme_minimal()  +
  theme(plot.title =element_text(size=16, face=&#39;bold&#39;,hjust = 0.5,margin = margin(10,0,10,0)),
        plot.subtitle =element_text(size=16, face=&#39;bold&#39;,hjust = 0.5), #put titles in the middle
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=12),
        axis.ticks.x = element_line(),
        axis.ticks.y=element_line(),
        axis.title.x = element_text(size=16,face=&#39;bold&#39;),
        axis.title.y = element_text(size=16,face=&#39;bold&#39;),
        ) +
  labs(title = &quot;Biden Net Approval Rate&quot;,
         subtitle = &quot;Weekly Average&quot;,
         x = &quot;Week&quot;,
         y = &quot;&quot;,
         caption = &quot;Source: https://projects.fivethirtyeight.com/biden-approval-ratings&quot;) +
  ylab(&quot;Average net approval rate&quot;)</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/plot%20the%20average%20net%20approval%20rate-1.png" width="1152" style="display: block; margin: auto;" /></p>
</div>
<div id="confidence-intervals-for-week-3-and-week-25" class="section level2">
<h2>Confidence Intervals for Week 3 and Week 25</h2>
<p>The confidence intervals for week 3 and week 25 are respectively the largest and the smallest. In week 3 the confidence interval ranges between 13 and 24, whereas in week 25 the lower bound is 10 and the upper bound 13. The difference is due to the sample size of the data. The much higher number of values for week 25 decreases exponentially the standard error, that is in fact 0.6 compared to the 2.5 for week 3.</p>
</div>
</div>
<div id="challenge-1-excess-rentals-in-tfl-bike-sharing" class="section level1">
<h1>Challenge 1: Excess rentals in TfL bike sharing</h1>
<p>Recall the TfL data on how many bikes were hired every single day. We can get the latest data by running the following codes:</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx&quot;

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp &lt;- tempfile(fileext = &quot;.xlsx&quot;)))</code></pre>
<pre><code>## Response [https://airdrive-secure.s3-eu-west-1.amazonaws.com/london/dataset/number-bicycle-hires/2021-09-23T12%3A52%3A20/tfl-daily-cycle-hires.xlsx?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJJDIMAIVZJDICKHA%2F20211018%2Feu-west-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20211018T021916Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=47ceed0425c6bd2aff31731cece943beecdca65a1feadaecad68e9061ccd312c&amp;X-Amz-SignedHeaders=host]
##   Date: 2021-10-18 02:19
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 174 kB
## &lt;ON DISK&gt;  C:\Users\lenovo\AppData\Local\Temp\RtmpGAtE1t\file46b86d7a1a63.xlsx</code></pre>
<pre class="r"><code># Use read_excel to read it as dataframe
bike0 &lt;- read_excel(bike.temp,
                   sheet = &quot;Data&quot;,
                   range = cell_cols(&quot;A:B&quot;))

# change dates to get year, month, and week
bike &lt;- bike0 %&gt;% 
  clean_names() %&gt;% 
  rename (bikes_hired = number_of_bicycle_hires) %&gt;% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))</code></pre>
<p>We can easily create a facet grid that plots bikes hired by month and year.</p>
<p>The distributions of bikes hired per month during May and Jun in 2020 is flatter compared with that of the previous years. The standard deviations of May and June, 2020, are also higher than the previous years, reflecting the fact that there more variations among days when very few bikes were rented and days when lots of bikes were rented. This wide dispersion is the evidence of Covid-19’s significant affect and restrictionson on people’s daily travel.</p>
<p>We then start to reproduce the following two graphs:</p>
<ol style="list-style-type: decimal">
<li><p>Monthly changes in TFL bike rentals between 2016 and 2019</p></li>
<li><p>TFL bike rentals’ weekly percentage changes from the expected rentals between 2016 and 2019.
The two grey shaded rectangles correspond to Q2 (weeks 14-26) and Q4 (weeks 40-52).</p></li>
</ol>
<p>For both of these graphs, we calculate the expected number of rentals per week or month between 2016-2019, and then see how each week/month of 2020-2021 compares to the expected rentals, using the calculation <code>excess_rentals = actual_rentals - expected_rentals</code>.</p>
<p>The mean of the number of bicycle hired is used to calculate the expected rentals, as mean takes the whole dataset into consideration and reprsents the average of the entire data.</p>
<p>Additionally, we uses these links as references when creating plots:</p>
<ul>
<li><a href="https://ggplot2.tidyverse.org/reference/geom_ribbon.html" class="uri">https://ggplot2.tidyverse.org/reference/geom_ribbon.html</a></li>
<li><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html" class="uri">https://ggplot2.tidyverse.org/reference/geom_tile.html</a></li>
<li><a href="https://ggplot2.tidyverse.org/reference/geom_rug.html" class="uri">https://ggplot2.tidyverse.org/reference/geom_rug.html</a></li>
</ul>
<p>We first calculate the mean of monthly number of bicycles hired between 2016 and 2019, and then get the monthly changes in TFL bike rentals using excess_rental method. We set “up” for the positive excess rental (when monthly actual_rentals is greater than expected_rentals), and “down” for the negative excess rental (when monthly actual_rentals is less than expected_rentals).</p>
<pre class="r"><code>bike_month_16_19 &lt;- bike %&gt;%
  filter(year&gt;=2016&amp;year&lt;=2019)%&gt;%
  group_by(month) %&gt;%
  summarise(expected_rental=mean(bikes_hired))


bike_month &lt;- bike %&gt;%
  filter(year&gt;=2016) %&gt;%
  group_by(year,month) %&gt;%
  summarise(bike_hired_month=mean(bikes_hired),.groups = &#39;drop&#39;)

bike_month_comp &lt;- merge(bike_month,bike_month_16_19,by=&quot;month&quot;) %&gt;%
  mutate(excess_rentals = bike_hired_month - expected_rental,
         up = ifelse(bike_hired_month&gt;expected_rental, excess_rentals, 0), #up gives the diffrence between actual and expected rentals when actual&gt;expected
         down = ifelse(bike_hired_month&lt;expected_rental, excess_rentals, 0)) #down gives the diffrence between actual and expected rentals when actual&lt;expected</code></pre>
<p>Then we use geom_line and geom_ribbon to generate the lines for expected rental. The green area represents the rental changes where the actual monthly number of bicycles hired is greater than the expected rental, and the red area appears when the actual monthly number of bicycles hired is less than the expected rental. The plots of monthly changes in Tfl bike rentals between 2016 and 2019 are illustrated below:</p>
<pre class="r"><code>ggplot(bike_month_comp,aes(month))+
  geom_line(aes(x=month,y=expected_rental,colour=&quot;Expected&quot;,group=year),size=1)+
  geom_line(aes(x=month,y=bike_hired_month,colour=&quot;Actual&quot;,group=year))+
  geom_ribbon(aes(ymin=expected_rental,
                  ymax=expected_rental+up,group=year),alpha=0.4,fill=&quot;#7DCD85&quot;)+ #plot the areas in green using up when actual&gt;expected
  geom_ribbon(aes(ymin=expected_rental+down,
                  ymax=expected_rental,group=year),alpha=0.4,fill=&quot;#CB454A&quot;)+ #plot the areas in red when using down actual&gt;expected
  scale_colour_manual(&quot;&quot;,breaks=c(&quot;Expected&quot;,&quot;Actual&quot;),values=c(&quot;blue&quot;,&quot;black&quot;))+ 
  facet_wrap(~year)+
  theme_minimal()  +
  theme(legend.position = &quot;none&quot;,
        plot.title =element_text(size=16, face=&#39;bold&#39;,hjust = 0,margin = margin(10,0,10,0)),
        plot.subtitle =element_text(size=16, hjust = 0), #put titles in the middle
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=12),
        axis.ticks.x = element_line(),
        axis.ticks.y=element_line(),
        axis.title.x = element_text(size=16,face=&#39;bold&#39;),
        axis.title.y = element_text(size=16,face=&#39;bold&#39;),
        ) +
  labs(title = &quot;Monthly changes in TfL bike rentals&quot;, 
       subtitle = &quot;Expected rentals shown in blue and calculated between 2016-2019, Actual rentals shown in black&quot;, 
       caption= &quot;Source: TfL, London Data Store&quot;,
       x=&quot;Month&quot;, y=&quot;Bike Rentals&quot;) </code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/plot%20monthly%20bike%20rental%20change-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We then calculate the mean of weekly number of bicycles hired, and the weekly percentage change between actual and expected bike rentals between 2016 and 2019. We set “up” for the positive percentage change (when weekly actual_rentals is greater than expected_rentals), and “down” for the negative percentage change (when weekly actual_rentals is less than expected_rentals).</p>
<pre class="r"><code>glimpse(bike)</code></pre>
<pre><code>## Rows: 4,051
## Columns: 5
## $ day         &lt;dttm&gt; 2010-07-30, 2010-07-31, 2010-08-01, 2010-08-02, 2010-08-0~
## $ bikes_hired &lt;dbl&gt; 6897, 5564, 4303, 6642, 7966, 7893, 8724, 9797, 6631, 7864~
## $ year        &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010~
## $ month       &lt;ord&gt; Jul, Jul, Aug, Aug, Aug, Aug, Aug, Aug, Aug, Aug, Aug, Aug~
## $ week        &lt;dbl&gt; 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32~</code></pre>
<pre class="r"><code>bike_week_16_19 &lt;- bike %&gt;%
  filter(year&gt;=2016&amp;year&lt;=2019)%&gt;%
  group_by(week) %&gt;%
  summarise(expected_rental=mean(bikes_hired))


bike_week &lt;- bike %&gt;%
  filter(year&gt;=2016) %&gt;%
  filter(!(year==2021&amp;week==53))%&gt;%
  group_by(year,week) %&gt;%
  summarise(bike_hired_week=mean(bikes_hired),.groups = &#39;drop&#39;)

bike_week_comp &lt;- merge(bike_week,bike_week_16_19,by=&quot;week&quot;) %&gt;%
  mutate(percentage_rentals_change = (bike_hired_week - expected_rental)/expected_rental,
         up = ifelse(bike_hired_week&gt;expected_rental, percentage_rentals_change, 0), #up gives the percentage diffrence between actual and expected rentals when actual&gt;expected
         down = ifelse(bike_hired_week&lt;expected_rental, percentage_rentals_change, 0)) #down gives the percentage diffrence between actual and expected rentals when actual&lt;expected</code></pre>
<p>The two grey shaded rectangles correspond to Q2 (weeks 14-26) and Q4 (weeks 40-52) are also added.</p>
<pre class="r"><code>ggplot(bike_week_comp,aes(week))+
  geom_rect(aes(xmin=14,xmax=26,ymin=-0.8,ymax=1.1,group=year),colour=&quot;grey&quot;,alpha=0.002)+ #plot rectangles for Q2 
  geom_rect(aes(xmin=40,xmax=52,ymin=-0.8,ymax=1.1,group=year),colour=&quot;grey&quot;,alpha=0.002)+ #plot rectangles for Q4
  geom_rug(aes(colour=ifelse(bike_hired_week&gt;=expected_rental,&quot;&gt;=0&quot;,&quot;&lt;0&quot;)),sides=&quot;b&quot;)+ #plot rug for x asis
  scale_colour_manual(values=c(&quot;#CB454A&quot;,&quot;#7DCD85&quot;),name=&quot;Actual vs Expected &quot;, guide=FALSE)+
  geom_line(aes(x=week,y=percentage_rentals_change,group=year),colour=&quot;black&quot;,size=0.5)+
  geom_ribbon(aes(ymin=0,
                  ymax=up,group=year),alpha=0.4,fill=&quot;#7DCD85&quot;)+ #plot the areas in green using up when actual&gt;expected
  geom_ribbon(aes(ymin=down,
                  ymax=0,group=year),alpha=0.4,fill=&quot;#CB454A&quot;)+ #plot the areas in red using up when actual&gt;expected
  facet_wrap(~year)+
  theme_minimal()  +
  theme(legend.position = &quot;none&quot;,
        plot.title =element_text(size=16, face=&#39;bold&#39;,hjust = 0,margin = margin(10,0,10,0)),
        plot.subtitle =element_text(size=16, hjust = 0), #put titles in the middle
        axis.text.x = element_text(size=10),
        axis.text.y = element_text(size=12),
        axis.ticks.x = element_line(),
        axis.ticks.y=element_line(),
        axis.title.x = element_text(size=16,face=&#39;bold&#39;),
        axis.title.y = element_text(size=16,face=&#39;bold&#39;),
        ) +
  labs(title = &quot;Weekly changes in TfL bike rentals&quot;, 
       subtitle = &quot;Percentage changes from the expected level of weekly rentals&quot;, caption= &quot;Source: TfL, London Data Store&quot;,
       x=&quot;Week&quot;, y=&quot;Percentage Change in Bike Rentals&quot;) +
  scale_x_continuous(breaks=c(0,13,26,39,53),limits=c(0,53))+
  scale_y_continuous(labels=scales::percent)</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/plot%20weekly%20bike%20rental%20change-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2-how-has-the-cpi-and-its-components-changed-over-the-last-few-years" class="section level1">
<h1>Challenge 2: How has the CPI and its components changed over the last few years?</h1>
<ol style="list-style-type: decimal">
<li>We scrape the FRED website and pull all of the CPI components into a vector.</li>
</ol>
<pre class="r"><code>library(rvest)
url &lt;- &quot;https://fredaccount.stlouisfed.org/public/datalist/843&quot;

tables &lt;- url %&gt;% 
  read_html() %&gt;% 
  html_nodes(css=&quot;table&quot;)

cpi &lt;- map(tables, . %&gt;% 
             html_table(fill=TRUE)%&gt;% 
             janitor::clean_names()) 

cpi_id = cpi[[2]]$series_id</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Once we have a vector of components, you can then pass it to <code>tidyquant::tq_get(get = "economic.data", from =  "2000-01-01")</code> to get all data since January 1, 2000</li>
</ol>
<pre class="r"><code>cpi_data &lt;- tidyquant::tq_get(cpi_id, get = &quot;economic.data&quot;, from =  &quot;2000-01-01&quot;)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Since the data you download is an index with various starting dates, we need to calculate the yearly, or 12-month change. To do this we need to use the <code>lag</code> function, and specifically, <code>year_change = value/lag(value, 12) - 1</code>; this means that we are comparing the current month’s value with that 12 months ago lag(value, 12).</li>
</ol>
<pre class="r"><code>cpi_data_clean &lt;- cpi_data %&gt;% pivot_wider(id_cols=1:3, 
               names_from=&quot;symbol&quot;, 
               values_from = &quot;price&quot;)

#Make date the index to make mutate_all work
cpi_data_clean1 &lt;- cpi_data_clean %&gt;% 
     remove_rownames() %&gt;%
     column_to_rownames(var = &#39;date&#39;)

#Define Function
Funk &lt;- function(x, na.rm = FALSE) (x/lag(x, 12) - 1)

#Apply functions to all columns into new dataset
cpi_changes &lt;- cpi_data_clean1 %&gt;%  mutate_all(
  Funk
)</code></pre>
<p>Below we format the graph</p>
<ol start="4" style="list-style-type: decimal">
<li>We order components so the higher the yearly change, the earlier does that component appear.</li>
<li>We also make sure that the <strong>All Items</strong> CPI (CPIAUCSL) appears first.</li>
<li>We then add a <code>geom_smooth()</code> for each component to get a sense of the overall trend.
7 Finally, we colour the points according to whether yearly change was positive or negative.</li>
</ol>
<pre class="r"><code># Make date back as first column for pivot_longer
cpi_changes &lt;- cbind(&quot;Date&quot; = rownames(cpi_changes), cpi_changes)

cpi_changes_graph &lt;- cpi_changes %&gt;% 
  pivot_longer(cols=2:50, 
               names_to=&quot;Component&quot;, 
               values_to = &quot;YoY&quot;)

cpi_changes_graph &lt;- cpi_changes_graph %&gt;% mutate(
  Neg = (YoY&lt;=0)
)

cpi_changes_graph$Date &lt;- as.Date(cpi_changes_graph$Date, &quot;%Y-%m-%d&quot;)

# Get our order of components by max descending (excl. All Items)
cpi_order &lt;- cpi_changes_graph %&gt;%
  filter(Date&gt;=&quot;2016-01-01&quot;) %&gt;%
  filter(Component != &quot;CPIAUCSL&quot;) %&gt;% 
  group_by(Component) %&gt;% 
  summarise(max_YoY = max(YoY,na.rm=TRUE)) %&gt;% 
  arrange(-max_YoY)

# Put the all items at the start (append)
order = c(cpi_order$Component)
order = append(&quot;CPIAUCSL&quot;, order)
order</code></pre>
<pre><code>##  [1] &quot;CPIAUCSL&quot;       &quot;CUSR0000SETB01&quot; &quot;CUSR0000SETB&quot;   &quot;CUSR0000SETA02&quot;
##  [5] &quot;CUSR0000SEHE&quot;   &quot;CUSR0000SETG01&quot; &quot;CUSR0000SAT1&quot;   &quot;CUSR0000SEHB&quot;  
##  [9] &quot;CPITRNSL&quot;       &quot;CUSR0000SEHF02&quot; &quot;CUSR0000SETA&quot;   &quot;CUSR0000SETG&quot;  
## [13] &quot;CUSR0000SAF112&quot; &quot;CUSR0000SAH21&quot;  &quot;CUSR0000SEAF&quot;   &quot;CUSR0000SETA01&quot;
## [17] &quot;CUSR0000SEHF&quot;   &quot;CUSR0000SAH2&quot;   &quot;CUSR0000SEAE&quot;   &quot;CUSR0000SEFS&quot;  
## [21] &quot;CUSR0000SETC&quot;   &quot;CUSR0000SEFJ&quot;   &quot;CPIAPPSL&quot;       &quot;CUSR0000SAF11&quot; 
## [25] &quot;CUSR0000SAA2&quot;   &quot;CUSR0000SEHF01&quot; &quot;CUSR0000SAF114&quot; &quot;CUSR0000SAH3&quot;  
## [29] &quot;CUSR0000SEFR&quot;   &quot;CUSR0000SEFV05&quot; &quot;CUSR0000SEFV&quot;   &quot;CPIUFDSL&quot;      
## [33] &quot;CUSR0000SEFT&quot;   &quot;CPIFABSL&quot;       &quot;CUSR0000SEHG&quot;   &quot;CUSR0000SAA1&quot;  
## [37] &quot;CUSR0000SETD&quot;   &quot;CUSR0000SAF115&quot; &quot;CUSR0000SEHA&quot;   &quot;CUSR0000SEFP01&quot;
## [41] &quot;CUSR0000SAF113&quot; &quot;CPIHOSSL&quot;       &quot;CUSR0000SAH1&quot;   &quot;CUSR0000SEHC01&quot;
## [45] &quot;CUSR0000SEHC&quot;   &quot;CUSR0000SEFX&quot;   &quot;CUSR0000SAF111&quot; &quot;CUSR0000SAF116&quot;
## [49] &quot;CUSR0000SEFW&quot;</code></pre>
<pre class="r"><code>cpi_changes_graph %&gt;%
  filter(Date&gt;=&quot;2016-01-01&quot;) %&gt;% 
  group_by(Component) %&gt;% 
  mutate(
    max_cpi = max(YoY)
  )</code></pre>
<pre><code>## # A tibble: 3,381 x 5
## # Groups:   Component [49]
##    Date       Component           YoY Neg   max_cpi
##    &lt;date&gt;     &lt;chr&gt;             &lt;dbl&gt; &lt;lgl&gt;   &lt;dbl&gt;
##  1 2016-01-01 CUSR0000SETG01 -0.0192  TRUE   0.246 
##  2 2016-01-01 CUSR0000SEFW    0.0102  FALSE  0.0289
##  3 2016-01-01 CUSR0000SEFX    0.0156  FALSE  0.0336
##  4 2016-01-01 CUSR0000SAF116  0.0120  FALSE  0.0298
##  5 2016-01-01 CPIAUCSL        0.0124  FALSE  0.0538
##  6 2016-01-01 CPIAPPSL       -0.00896 TRUE   0.0557
##  7 2016-01-01 CUSR0000SAF111  0.00355 FALSE  0.0329
##  8 2016-01-01 CUSR0000SEFP01 -0.0262  TRUE   0.0395
##  9 2016-01-01 CUSR0000SEFJ   -0.0297  TRUE   0.0568
## 10 2016-01-01 CUSR0000SEHF01 -0.0231  TRUE   0.0524
## # ... with 3,371 more rows</code></pre>
<pre class="r"><code># Graph
cpi_changes_graph %&gt;%
  filter(Date&gt;=&quot;2016-01-01&quot;) %&gt;% 
  ggplot(aes(Date, YoY)) + 
  geom_point(size=1, aes(colour = Neg)) +
  geom_smooth(se=F, colour=&quot;grey&quot;) +
  facet_wrap(~factor(Component, levels = order),scales=&quot;free&quot;)+
  scale_y_continuous(labels = scales::percent)+
  scale_x_date(breaks = as.Date(c(&quot;2016-01-01&quot;, &quot;2018-01-01&quot;,&quot;2020-01-01&quot;)), labels=c(&quot;2016&quot;, &quot;2018&quot;, &quot;2020&quot;),
               minor_breaks = as.Date(c(&quot;2016-01-01&quot;, &quot;2018-01-01&quot;,
                                        &quot;2020-01-01&quot;)))+
  theme_bw()+
  theme(legend.title = element_blank(),legend.position = &quot;none&quot;,
        axis.text.x = element_text(size=5, colour = &quot;black&quot;), 
    axis.text.y = element_text(size=5, colour = &quot;black&quot;),
    plot.title = element_text(size=14, face= &quot;bold&quot;, colour= &quot;black&quot;),
    plot.subtitle = element_text(size=10, colour= &quot;black&quot;),
    axis.title.x = element_text(size=10, colour = &quot;black&quot;),    
    axis.title.y = element_text(size=10, colour = &quot;black&quot;))+
  
  labs(title=&quot;Yearly change of US CPI (All Items) and its components&quot;, 
       subtitle = &quot;Year on year change being positive or negative
Jan 2016 to Aug 2021&quot;, 
       x=&quot;Year&quot;, 
       y=&quot;YoY % Change&quot;)</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/format%20the%20graph-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p>As you can see, we get a similar graph to the target figure below, with identical layout of the facetted graphs. Note that the individual graph headings below were not available in the dataset scraped from FRED, so we used the component IDs instead.
<img src="C:/Users/lenovo/Desktop/R/personal-site/images_project/cpi_components_since_2016.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We now graph the major categories (Housing, Transportation, Food and beverages, Medical care, Education and communication, Recreation, and Apparel), sorted according to their relative importance.</p>
<pre class="r"><code># Get the codes/series ids for the relevant names
# &quot;Consumer Price Index for All Urban Consumers: Housing in U.S. City Average&quot;             # 42.385, CPIHOSSL
# &quot;Consumer Price Index for All Urban Consumers: Transportation in U.S. City Average&quot;      # 15.160, CPITRNSL
# &quot;Consumer Price Index for All Urban Consumers: Food and Beverages in U.S. City Average&quot;  # 15.157, CPIFABSL
# &quot;Consumer Price Index for All Urban Consumers: Apparel in U.S. City Average&quot;             # 2.663,  CPIAPPSL
# No education, communication, and recreation info in dataset

important_components = c(&quot;CPIAUCSL&quot;, &quot;CPIHOSSL&quot;, &quot;CPITRNSL&quot;, &quot;CPIFABSL&quot;, &quot;CPIAPPSL&quot;) # Included overall figure also

# Graph
cpi_changes_graph %&gt;%
  filter(Date&gt;=&quot;2016-01-01&quot;) %&gt;% 
  filter(Component==important_components) %&gt;% 
  ggplot(aes(Date, YoY)) + 
  geom_point(size=2, aes(colour = Neg)) +
  geom_smooth(se=F, colour=&quot;grey&quot;) +
  facet_wrap(~factor(Component, levels = important_components),scales=&quot;free&quot;, ncol=1)+
  scale_y_continuous(labels = scales::percent)+
  scale_x_date(breaks = as.Date(c(&quot;2016-01-01&quot;, &quot;2018-01-01&quot;,&quot;2020-01-01&quot;)), labels=c(&quot;2016&quot;, &quot;2018&quot;, &quot;2020&quot;),
               minor_breaks = as.Date(c(&quot;2016-01-01&quot;, &quot;2018-01-01&quot;,
                                        &quot;2020-01-01&quot;)))+
  theme_bw()+
  theme(legend.title = element_blank(),legend.position = &quot;none&quot;,
        axis.text.x = element_text(size=5, colour = &quot;black&quot;), 
    axis.text.y = element_text(size=5, colour = &quot;black&quot;),
    plot.title = element_text(size=14, face= &quot;bold&quot;, colour= &quot;black&quot;),
    plot.subtitle = element_text(size=10, colour= &quot;black&quot;),
    axis.title.x = element_text(size=10, colour = &quot;black&quot;),    
    axis.title.y = element_text(size=10, colour = &quot;black&quot;))+
  
  labs(title=&quot;Yearly change of US CPI and selected components of US CPI&quot;, 
       subtitle = &quot;Year on year change being positive or negative Jan 2016 to Aug 2021. Ranked in order of relative importantce&quot;, 
       x=&quot;Year&quot;, 
       y=&quot;YoY % Change&quot;)</code></pre>
<p><img src="/project/CA09_Homework2_Group%20B3-V2_files/figure-html/plot%20yearly%20change%20in%20CPI%20using%20major%20categories-1.png" width="1152" style="display: block; margin: auto;" /></p>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Catherine Xinyue Zhang, Doris Liu, Ismail Riahi, Ivo Margetich, Jacopo Lorusso Caputi, John Purcell, Parthivi Bansal (Alphabetical order)</li>
<li>Approximately how much time did you spend on this problem set: 12 hours</li>
<li>What, if anything, gave you the most trouble: Details of different functions in plots</li>
</ul>
<blockquote>
<p>As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?
Yes</p>
</blockquote>
</div>
